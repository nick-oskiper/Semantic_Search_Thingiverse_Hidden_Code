{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Only the main process_and_describe function is shown.\n",
    "\n",
    "This code below (generate_description_main.py) takes 3D models' downloaded files from the Thingiverse scraper and uses GenAI to generate: \n",
    "1. a description using either provided image files or blender snapshots\n",
    "2. A category for the model\n",
    "3. tags for the model\n",
    "\n",
    "This outputs a csv with the generated information for each model and can be paused at any time (since it costs money).\n",
    "This can be skipped as there are around 540 models in the csv, but can be run if more want to be loaded. The output csv has id,description,name,category,tags"
   ],
   "id": "7210382cc8953710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:42:35.834430Z",
     "start_time": "2025-01-07T17:42:35.821958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def process_and_describe(client, repo_owner, repo_name, local_extract_path, subdir, csv_writer, existing_ids, save_images=True):\n",
    "#     \"\"\"\n",
    "#     Processes and describes each model in the repository.\n",
    "# \n",
    "#     Parameters:\n",
    "#     - client (OpenAIClient): Instance of OpenAIClient.\n",
    "#     - repo_owner (str): Owner of the repository.\n",
    "#     - repo_name (str): Name of the repository.\n",
    "#     - local_extract_path (str): Path where files are extracted.\n",
    "#     - subdir (dict): Information about the subdirectory.\n",
    "#     - csv_writer (csv.writer): CSV writer object.\n",
    "#     - existing_ids (set): Set of already processed object IDs.\n",
    "#     - save_images (bool): Whether to save processed images.\n",
    "#     \"\"\"\n",
    "#     subdir_path = os.path.join(local_extract_path, subdir['path'])\n",
    "#     os.makedirs(subdir_path, exist_ok=True)\n",
    "# \n",
    "#     try:\n",
    "#         files = list_files_in_repo(repo_owner, repo_name, subdir['path'])\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error listing files in subdir {subdir['path']}: {e}\")\n",
    "#         return\n",
    "# \n",
    "#     if not files:\n",
    "#         print(\"No files found in the repository.\")\n",
    "#         return\n",
    "# \n",
    "#     print(f\"Found {len(files)} items in {subdir['path']} directory.\")\n",
    "#     for file_info in files:\n",
    "#         if file_info['type'] == 'file' and file_info['name'].endswith('.zip'):\n",
    "#             zip_path = os.path.join(subdir_path, file_info['name'])  # Path of zip file\n",
    "#             try:\n",
    "#                 download_file(file_info['download_url'], zip_path)  # Downloads file at path\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Skipping file due to download error: {zip_path} - {e}\")\n",
    "#                 continue\n",
    "# \n",
    "#             extract_zip(zip_path, subdir_path)  # Extracts zip to subdir\n",
    "#             images_dir = os.path.join(subdir_path, 'images')\n",
    "#             image_files = find_image_files(images_dir)  # Finds all images for each item\n",
    "# \n",
    "#             # Define the exclusion list\n",
    "#             BROAD_TAGS_EXCLUSION = [\n",
    "#                 \"3d model\", \"fully assembled\", \"complete\", \"model\", \"assembly\",\n",
    "#                 \"thing\", \"object\", \"product\", \"item\", \"prototype\"\n",
    "#             ]\n",
    "# \n",
    "#             if not image_files:\n",
    "#                 print(f\"No image files found in {zip_path}. Attempting to render using Blender.\")\n",
    "#                 # Locate the .stl or .obj file under 'files/' subdirectory\n",
    "#                 files_subdir = os.path.join(subdir_path, 'files')\n",
    "#                 if not os.path.isdir(files_subdir):\n",
    "#                     print(f\"No 'files/' directory found in {zip_path}. Skipping.\")\n",
    "#                     continue\n",
    "# \n",
    "#                 # Find all .stl and .obj files in 'files/' directory\n",
    "#                 model_files = [f for f in os.listdir(files_subdir) if f.lower().endswith(('.stl', '.obj'))]\n",
    "#                 if not model_files:\n",
    "#                     print(f\"No .stl or .obj files found in 'files/' directory of {zip_path}. Skipping.\")\n",
    "#                     continue\n",
    "# \n",
    "#                 # For simplicity, process the first .stl/.obj file found\n",
    "#                 model_file = os.path.join(files_subdir, model_files[0])\n",
    "#                 print(f\"Found model file: {model_file}\")\n",
    "# \n",
    "#                 # Define paths for Blender executable and script\n",
    "#                 blender_executable = r\"C:\\Program Files\\Blender Foundation\\Blender 4.2\\blender.exe\"  # Update if different\n",
    "#                 blender_script = \n",
    "#                 rendered_image_path = os.path.join(subdir_path, 'rendered_image.png')\n",
    "# \n",
    "#                 # Call Blender to render the image\n",
    "#                 rendered_image = render_model_with_blender(\n",
    "#                     blender_executable,\n",
    "#                     blender_script,\n",
    "#                     model_file,\n",
    "#                     rendered_image_path\n",
    "#                 )\n",
    "# \n",
    "#                 if rendered_image and os.path.exists(rendered_image):\n",
    "#                     image_to_use = rendered_image\n",
    "#                 else:\n",
    "#                     print(f\"Failed to render image for {zip_path}. Skipping.\")\n",
    "#                     continue\n",
    "#             else:\n",
    "#                 # Use the largest image file if no combined image is found\n",
    "#                 image_to_use = find_largest_image_file(image_files)\n",
    "#                 if not image_to_use:\n",
    "#                     print(f\"No suitable image found in {zip_path}\")\n",
    "#                     continue\n",
    "# \n",
    "#             # Log the image being processed\n",
    "#             print(f\"Processing image: {image_to_use}\")\n",
    "# \n",
    "#             # Extract keywords from the zip file name and add new keywords\n",
    "#             zip_file_name = os.path.splitext(file_info['name'])[0]\n",
    "#             keywords = zip_file_name.replace('-', ' ').replace('_', ' ').split()\n",
    "#             keywords.extend([\"complete\", \"assembled\", \"whole\", \"IMG_\"])  # Keywords include name and these\n",
    "# \n",
    "#             # Generate initial guess based on the directory name\n",
    "#             initial_guess = \" \".join(keywords).capitalize()\n",
    "# \n",
    "#             # Extract object_id from the zip file name\n",
    "#             id_extracted = extract_id_from_name(zip_file_name)\n",
    "#             if not id_extracted:\n",
    "#                 print(f\"Could not extract ID from zip file name: {zip_file_name}. Skipping.\")\n",
    "#                 continue\n",
    "#             id = id_extracted\n",
    "# \n",
    "#             # Check if object_id already exists\n",
    "#             if id in existing_ids:\n",
    "#                 print(f\"Object ID {id} already exists in CSV. Skipping.\")\n",
    "#                 continue\n",
    "# \n",
    "#             # Generate description, category, and tags using OpenAI\n",
    "#             ai_data = client.describe_image_model(image_to_use, initial_guess)\n",
    "#             if ai_data:\n",
    "#                 description = ai_data.get('description', '').strip()\n",
    "#                 category = ai_data.get('category', '').strip()\n",
    "#                 tags = ai_data.get('tags', [])\n",
    "# \n",
    "#                 if not description or not category or not tags:\n",
    "#                     print(f\"Incomplete AI data for {image_to_use}. Skipping.\")\n",
    "#                     continue\n",
    "# \n",
    "#                 # Filter out broad/generic tags\n",
    "#                 filtered_tags = filter_tags(tags, BROAD_TAGS_EXCLUSION)\n",
    "# \n",
    "#                 # If no tags remain after filtering, assign a default tag\n",
    "#                 if not filtered_tags:\n",
    "#                     print(f\"All tags for {image_to_use} were broad. Assigning default tag 'unknown'.\")\n",
    "#                     filtered_tags = [\"unknown\"]\n",
    "# \n",
    "#                 # Format tags as comma-separated string\n",
    "#                 tags_str = \", \".join(filtered_tags)\n",
    "# \n",
    "#                 print(f\"Description for {image_to_use}:\\n{description}\\n\")\n",
    "#                 print(f\"Category: {category}\")\n",
    "#                 print(f\"Tags: {tags_str}\\n\")\n",
    "# \n",
    "#                 # Derive name from the zip file name or any other logic\n",
    "#                 name = \" \".join(keywords).capitalize()\n",
    "# \n",
    "#                 # Write object_id, description, name, category, tags to CSV\n",
    "#                 csv_writer.writerow([id, description, name, category, tags_str])\n",
    "#                 print(f\"Wrote data for Object ID {id} to CSV.\\n\")\n",
    "# \n",
    "#                 # Add to existing_ids to prevent reprocessing within the same run\n",
    "#                 existing_ids.add(id)\n",
    "# \n",
    "#             # Save a copy of the image being processed for visual inspection if save_images is True\n",
    "#             if save_images:\n",
    "#                 try:\n",
    "#                     output_dir = os.path.join(local_extract_path, 'processed_images')  # Puts them to processed_images\n",
    "#                     os.makedirs(output_dir, exist_ok=True)\n",
    "#                     img_output_path = os.path.join(output_dir, os.path.basename(image_to_use))  # Good for verifying correctness of GPT\n",
    "# \n",
    "#                     # Ensure path length is within acceptable limits\n",
    "#                     if len(img_output_path) > 255:\n",
    "#                         print(f\"Path too long: {img_output_path}\")\n",
    "#                         continue\n",
    "# \n",
    "#                     # Save the image file\n",
    "#                     with open(image_to_use, 'rb') as img_file:\n",
    "#                         with open(img_output_path, 'wb') as output_file:\n",
    "#                             output_file.write(img_file.read())\n",
    "#                     print(f\"Saved processed image to: {img_output_path}\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error saving image {image_to_use}: {e}\")\n",
    "# \n",
    "#             # Pause to manage load\n",
    "#             time.sleep(1)"
   ],
   "id": "3f9e165258fee3be",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Below is build_graph_with_AI.py, which constructs a knowledge graph using the AI descriptions, categories, and tag similarities. Because it extracts this information from the csv that is generated in the above code, make sure that the correct path is set.\n",
    "\n",
    "### Only main function and output are shown.\n",
    "\n",
    "This is the main system that was implemented for this entire project, as it uses AI and a knowledge graph to improve search functions."
   ],
   "id": "4ec000bc97ea5169"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T18:33:11.053810Z",
     "start_time": "2024-12-18T18:32:27.669337Z"
    }
   },
   "source": [
    "# def main(csv_path, k_threshold=True, k=1):\n",
    "#     \"\"\"\n",
    "#     Main function to orchestrate the semantic network construction.\n",
    "# \n",
    "#     Parameters:\n",
    "#     - csv_path (str): Path to the CSV file containing model descriptions.\n",
    "#     - k_threshold (bool): If True, apply dynamic thresholding using mean + k*std.\n",
    "#                            If False, do not apply dynamic thresholding.\n",
    "#     - k (float): The multiplier for the standard deviation in threshold calculation.\n",
    "#                Relevant only if k_threshold is True.\n",
    "# \n",
    "#     The function performs the following steps:\n",
    "#     1. Connects to Neo4j.\n",
    "#     2. Loads and preprocesses data.\n",
    "#     3. Extracts key components and expands synonyms.\n",
    "#     4. Performs Named Entity Recognition.\n",
    "#     5. Weights primary nouns in descriptions.\n",
    "#     6. Calculates various similarity measures and combines them.\n",
    "#     7. Constructs the knowledge graph in Neo4j with nodes and edges.\n",
    "#     8. Applies additional optimizations like pruning and clustering.\n",
    "#     \"\"\"\n",
    "#     print(\"Starting semantic network construction process.\")\n",
    "# \n",
    "#     # Step 1: Connect to Neo4j\n",
    "#     graph_db = connect_to_neo4j(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "# \n",
    "#     # Step 2: Load Data\n",
    "#     df = load_data(csv_path)\n",
    "# \n",
    "#     # Step 3: Preprocess Data\n",
    "#     df = preprocess_dataframe(df)\n",
    "# \n",
    "#     # Step 4: Extract Key Components\n",
    "#     df = extract_key_nouns_adjectives(df)\n",
    "#     df, synonym_dict = expand_synonyms(df)\n",
    "#     df = perform_ner(df)\n",
    "# \n",
    "#     # Step 5: Preprocess Descriptions to Weight Primary Nouns and Incorporate Synonyms\n",
    "#     df = duplicate_primary_nouns(df, weight=2.0)\n",
    "# \n",
    "#     # Step 6: Text Similarity Calculation\n",
    "#     tfidf_matrix, tfidf_vectorizer = compute_tfidf(df)\n",
    "#     cosine_sim = compute_cosine_similarity_matrix(tfidf_matrix)\n",
    "# \n",
    "#     # Compute Sentence-BERT similarity using weighted_description\n",
    "#     embedding_sim = compute_sentence_transformer_similarity(df)\n",
    "# \n",
    "#     # Compute Category similarity\n",
    "#     category_sim = compute_category_similarity(df)\n",
    "# \n",
    "#     # Compute Tag similarity\n",
    "#     tag_sim = compute_tag_similarity(df)\n",
    "# \n",
    "#     # Combine all similarities into a hybrid matrix\n",
    "#     # Adjust weights as necessary to prioritize different components\n",
    "#     final_sim = hybrid_similarity(\n",
    "#         cosine_sim, embedding_sim, category_sim, tag_sim,\n",
    "#         weight_cosine=0.3, weight_embedding=0.5,\n",
    "#         weight_category=0.1, weight_tags=0.1\n",
    "#     )\n",
    "# \n",
    "#     # Adjust similarity scores based on primary nouns\n",
    "#     final_sim = adjust_similarity_with_primary_nouns(df, final_sim, boost=1.2, penalize=0.8)\n",
    "# \n",
    "#     # Adjust similarity scores based on entities\n",
    "#     final_sim = adjust_similarity_with_entities(df, final_sim, boost=1.2, penalize=0.8)\n",
    "# \n",
    "#     # Normalize the final similarity matrix\n",
    "#     final_sim = normalize_similarity(final_sim)\n",
    "# \n",
    "#     # Analyze similarity scores\n",
    "#     analyze_similarity_scores(final_sim)\n",
    "# \n",
    "#     # Determine dynamic threshold if enabled\n",
    "#     if k_threshold:\n",
    "#         dynamic_threshold = determine_threshold_mean_std(final_sim, k=k)  # Can adjust k as needed\n",
    "#     else:\n",
    "#         dynamic_threshold = 0.0  # No thresholding; connect all relevant edges\n",
    "# \n",
    "#     # Visualize similarity distribution with threshold\n",
    "#     visualize_similarity_distribution(\n",
    "#         final_sim,\n",
    "#         threshold=dynamic_threshold if k_threshold else None\n",
    "#     )\n",
    "# \n",
    "#     # Step 7: Knowledge Graph Construction with Embeddings\n",
    "#     model = SentenceTransformer('all-MiniLM-L6-v2')  # Initialize Sentence-BERT model\n",
    "#     create_nodes_with_embeddings(graph_db, df, model)\n",
    "# \n",
    "#     # Step 8: Create Edges Based on Similarity\n",
    "#     create_edges_batch(graph_db, df, final_sim, threshold=dynamic_threshold)  # Apply dynamic threshold\n",
    "# \n",
    "#     # Step 9: Additional Optimizations\n",
    "#     graph_pruning(\n",
    "#         graph_db,\n",
    "#         threshold=dynamic_threshold if k_threshold else 0.0\n",
    "#     )  # Prune edges below the dynamic threshold\n",
    "#     node_clustering(\n",
    "#         graph_db, df, final_sim, threshold=dynamic_threshold\n",
    "#     )  # Cluster based on dynamic threshold\n",
    "# \n",
    "#     print(\"Knowledge graph construction complete.\")\n",
    "# \n",
    "# \n",
    "# if __name__ == \"__main__\":\n",
    "#     # Set k_threshold=True to enable dynamic thresholding\n",
    "#     # Set k_threshold=False to disable dynamic thresholding\n",
    "#     # Adjust k as needed (e.g., k=1 for mean + 1*std)\n",
    "#     main(CSV_PATH, k_threshold=True, k=2)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noski\\PycharmProjects\\Semantic_Search_Thingiverse\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\noski\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\noski\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\noski\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\noski\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy Pipeline Components: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "Starting semantic network construction process.\n",
      "An unexpected error occurred while connecting to Neo4j: Cannot connect to any known routers\n",
      "Loaded data with 539 records.\n",
      "Starting text preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Text: 100%|██████████| 539/539 [00:03<00:00, 177.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed text preprocessing.\n",
      "Extracting key nouns and adjectives with primary noun identification...\n",
      "Completed extraction of key nouns and adjectives with multiple primary nouns.\n",
      "Expanding nouns and adjectives with filtered synonyms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Synonyms: 100%|██████████| 2385/2385 [00:01<00:00, 1231.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed expanding synonyms with filtering.\n",
      "Performing Named Entity Recognition (NER)...\n",
      "Completed NER.\n",
      "Duplicating primary nouns with weight=2.0...\n",
      "Completed duplicating primary nouns and incorporating synonyms.\n",
      "Computing TF-IDF vectors on weighted descriptions...\n",
      "Completed TF-IDF computation.\n",
      "Computing cosine similarity matrix...\n",
      "Completed cosine similarity computation.\n",
      "Computing Sentence-BERT similarity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noski\\PycharmProjects\\Semantic_Search_Thingiverse\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31ba88be965c4eb0aab4fe9bc4a6c6b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Sentence-BERT similarity computation.\n",
      "Computing category similarity matrix...\n",
      "Completed category similarity computation.\n",
      "Computing tag similarity matrix using Jaccard similarity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Tag Similarity: 100%|██████████| 539/539 [00:00<00:00, 4498.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed tag similarity computation.\n",
      "Combining cosine, embedding, category, and tag similarities into a hybrid similarity matrix...\n",
      "Completed hybrid similarity computation.\n",
      "Adjusting similarity scores based on primary nouns...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed adjusting similarity scores based on primary nouns.\n",
      "Adjusting similarity scores based on entity types...\n",
      "Completed adjusting similarity scores based on entity types.\n",
      "Analyzing similarity scores distribution...\n",
      "Similarity Scores - Min: 0.0000, Max: 0.9929, Mean: 0.1982, Median: 0.1782, Std: 0.0841\n",
      "Determining threshold based on mean + 2*std of similarity scores...\n",
      "Threshold set at mean (0.1982) + 2*std (0.0841) = 0.3663\n",
      "Saved similarity scores distribution with threshold plot as 'similarity_scores_distribution_with_threshold.png'.\n",
      "Creating nodes in Neo4j with embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noski\\PycharmProjects\\Semantic_Search_Thingiverse\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72abaaabde2847d3aeb05630a96bcab0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing Nodes: 100%|██████████| 539/539 [00:00<00:00, 34353.42it/s]\n",
      "Merging Nodes in Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating nodes with embeddings: 'NoneType' object has no attribute 'run'\n",
      "Creating edges in Neo4j in batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Pairs: 100%|██████████| 144991/144991 [00:00<00:00, 2607978.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error inserting batch of relationships: 'NoneType' object has no attribute 'begin'\n",
      "Inserted batch of 1000 relationships.\n",
      "Error inserting batch of relationships: 'NoneType' object has no attribute 'begin'\n",
      "Inserted batch of 1000 relationships.\n",
      "Error inserting batch of relationships: 'NoneType' object has no attribute 'begin'\n",
      "Inserted batch of 1000 relationships.\n",
      "Error inserting batch of relationships: 'NoneType' object has no attribute 'begin'\n",
      "Inserted batch of 1000 relationships.\n",
      "Error inserting batch of relationships: 'NoneType' object has no attribute 'begin'\n",
      "Inserted final batch of 909 relationships.\n",
      "Total edges created: 4909\n",
      "Completed edge creation in Neo4j.\n",
      "Pruning graph edges with similarity below 0.3663047495545203...\n",
      "Error during graph pruning: 'NoneType' object has no attribute 'run'\n",
      "Performing node clustering using NetworkX and Louvain method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Edges to Graph: 100%|██████████| 144991/144991 [00:00<00:00, 2947810.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 30 communities.\n",
      "Updating Neo4j nodes with community labels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating Communities:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during node clustering: 'NoneType' object has no attribute 'run'\n",
      "Knowledge graph construction complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Lastly, below is the code that allows the user to search for their specific model (model_search.py) using the knowledge graph constructed above. There is also filtering, selection, research, and other useful functionalities.\n",
    "\n",
    "### Only main function and output are shown.\n"
   ],
   "id": "3c3c43e2e7dcadfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T21:17:57.118405Z",
     "start_time": "2024-12-09T21:17:24.242458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def main():\n",
    "#     \"\"\"\n",
    "#     Main function to handle user queries and perform search on the knowledge graph with cascading filtering.\n",
    "#     \"\"\"\n",
    "#     print(\"Initializing Semantic Search on Knowledge Graph...\")\n",
    "# \n",
    "#     # Connect to Neo4j\n",
    "#     graph_db = connect_to_neo4j(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "# \n",
    "#     # Fetch all models with embeddings\n",
    "#     df_models = fetch_all_models(graph_db)\n",
    "# \n",
    "#     # Extract embeddings as a 2D numpy array\n",
    "#     model_embeddings = np.stack(df_models['embedding'].values)\n",
    "# \n",
    "#     # Load Sentence Transformer model\n",
    "#     print(\"Loading SentenceTransformer model...\")\n",
    "#     model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#     print(\"Model loaded successfully.\")\n",
    "# \n",
    "#     while True:\n",
    "#         # Prompt user for input\n",
    "#         user_query = input(\"\\nEnter your search query (or type 'exit' to quit): \").strip()\n",
    "#         if user_query.lower() == 'exit':\n",
    "#             print(\"Exiting Semantic Search. Goodbye!\")\n",
    "#             break\n",
    "#         if not user_query:\n",
    "#             print(\"Empty query. Please enter a valid search term.\")\n",
    "#             continue\n",
    "# \n",
    "#         # Preprocess the query with dynamic prioritization\n",
    "#         preprocessed_query = preprocess_text(user_query)\n",
    "#         if not preprocessed_query:\n",
    "#             print(\"Failed to preprocess the query. Please try a different input.\")\n",
    "#             continue\n",
    "# \n",
    "#         # Encode the query\n",
    "#         query_embedding = model.encode(preprocessed_query, show_progress_bar=False)\n",
    "# \n",
    "#         # Compute cosine similarity\n",
    "#         print(\"Computing similarities...\")\n",
    "#         similarities = compute_cosine_similarity(query_embedding, model_embeddings)\n",
    "# \n",
    "#         if similarities.size == 0:\n",
    "#             print(\"Failed to compute similarities.\")\n",
    "#             continue\n",
    "# \n",
    "#         # Display the top-k results\n",
    "#         top_k = 10  # Number of top results to retrieve\n",
    "#         top_results = display_results(df_models, similarities, top_k=top_k)\n",
    "# \n",
    "#         if top_results is None or top_results.empty:\n",
    "#             print(\"No similar models found.\")\n",
    "#             continue\n",
    "# \n",
    "#         # Initialize the current search scope with the initial top results\n",
    "#         current_scope = top_results\n",
    "# \n",
    "#         while True:\n",
    "#             # Prompt user to apply further filters or select a model\n",
    "#             selected = prompt_filter(current_scope)\n",
    "#             if selected == 'yes':\n",
    "#                 # User wants to filter further\n",
    "#                 # Prompt to select a model from current_scope\n",
    "#                 try:\n",
    "#                     selection = int(input(f\"Select a model to filter by (1-{len(current_scope)}): \").strip())\n",
    "#                     if 1 <= selection <= len(current_scope):\n",
    "#                         selected_model = current_scope.iloc[selection - 1]\n",
    "#                         selected_model_id = selected_model['id']\n",
    "#                         print(f\"\\nSelected Model ID: {selected_model_id} - {selected_model['name'] if pd.notnull(selected_model['name']) else 'N/A'}\")\n",
    "#                     else:\n",
    "#                         print(f\"Please enter a number between 1 and {len(current_scope)}.\")\n",
    "#                         continue\n",
    "#                 except ValueError:\n",
    "#                     print(\"Invalid input. Please enter a valid number.\")\n",
    "#                     continue\n",
    "# \n",
    "#                 # Fetch similar models to the selected model from the graph\n",
    "#                 similar_df = fetch_similar_models_from_graph(graph_db, selected_model_id)\n",
    "# \n",
    "#                 if similar_df.empty:\n",
    "#                     print(\"No further models found based on your selection.\")\n",
    "#                     break  # Exit filtering loop\n",
    "# \n",
    "#                 # Display the new set of similar models\n",
    "#                 print(f\"\\nModels similar to Model ID: {selected_model_id}:\")\n",
    "#                 similar_top_k = 10  # Number of top similar models to display\n",
    "#                 similar_top_results = display_results(similar_df, similar_df['similarity'].values, top_k=similar_top_k)\n",
    "# \n",
    "#                 if similar_top_results is None or similar_top_results.empty:\n",
    "#                     print(\"No similar models found in this step.\")\n",
    "#                     break  # Exit filtering loop\n",
    "# \n",
    "#                 # Update the current scope to the new similar models\n",
    "#                 current_scope = similar_top_results\n",
    "# \n",
    "#             elif selected == 'no':\n",
    "#                 # User does not want to filter further\n",
    "#                 break  # Exit filtering loop\n",
    "#             else:\n",
    "#                 # User selected a model by rank to view its full summary\n",
    "#                 selected_model_id = selected\n",
    "#                 # Fetch the full details of the selected model\n",
    "#                 try:\n",
    "#                     query = \"\"\"\n",
    "#                     MATCH (m:Model {id: $selected_id})\n",
    "#                     RETURN m.id AS id, m.name AS name, m.description AS description, m.category AS category, m.tags AS tags\n",
    "#                     \"\"\"\n",
    "#                     record = graph_db.run(query, selected_id=selected_model_id).data()\n",
    "#                     if not record:\n",
    "#                         print(f\"No details found for Model ID: {selected_model_id}.\")\n",
    "#                     else:\n",
    "#                         model_details = record[0]\n",
    "#                         print(f\"\\n--- Full Summary of Selected Model ---\")\n",
    "#                         print(f\"ID: {model_details['id']}\")\n",
    "#                         print(f\"Name: {model_details['name'] if pd.notnull(model_details['name']) else 'N/A'}\")\n",
    "#                         print(f\"Category: {model_details['category'] if pd.notnull(model_details['category']) else 'N/A'}\")\n",
    "#                         print(f\"Tags: {model_details['tags'] if pd.notnull(model_details['tags']) else 'N/A'}\")\n",
    "#                         print(f\"Description: {model_details['description'] if pd.notnull(model_details['description']) else 'N/A'}\")\n",
    "#                         print(f\"---------------------------------------\\n\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error fetching model details: {e}\")\n",
    "# \n",
    "#                 # After displaying the summary, ask if the user wants another search\n",
    "#                 while True:\n",
    "#                     another_search = input(\"Do you want to perform another search? (yes/no): \").strip().lower()\n",
    "#                     if another_search in ['yes', 'y']:\n",
    "#                         break  # Break to the main search loop\n",
    "#                     elif another_search in ['no', 'n']:\n",
    "#                         print(\"Exiting Semantic Search. Goodbye!\")\n",
    "#                         sys.exit(0)\n",
    "#                     else:\n",
    "#                         print(\"Please answer with 'yes' or 'no'.\")\n",
    "#                 break  # Exit filtering loop to perform another search\n",
    "# \n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ],
   "id": "f4a7b634777c43ac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\noski\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\noski\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Semantic Search on Knowledge Graph...\n",
      "Successfully connected to Neo4j.\n",
      "Fetching all models and their embeddings from Neo4j...\n",
      "Fetched 539 models with embeddings.\n",
      "Loading SentenceTransformer model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noski\\PycharmProjects\\Semantic_Search_Thingiverse\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Computing similarities...\n",
      "\n",
      "Top 10 similar models:\n",
      "\n",
      "Rank 1:\n",
      "ID: 4673220\n",
      "Name: Cow farts 2 2551620 complete assembled whole img_\n",
      "Category: Animals\n",
      "Tags: holstein cow,livestock,farm animal,realistic texture,standing posture\n",
      "Similarity Score: 0.5953\n",
      "Description: This is a realistic rendering of a dairy cow, standing on all fours with a life-like posture. The cow features prominent black and white markings, typical of the Holstein breed. Its body is robust with a well-defined head, alert ears, and expressive eyes. The legs are sturdy, supporting its heavy frame, and the tail is accurately positioned with a natural curve. Textures on the cow simulate a smooth and realistic hide finish.\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank 2:\n",
      "ID: 4734034\n",
      "Name: The cow 4811559 complete assembled whole img_\n",
      "Category: Animals\n",
      "Tags: cow,bovine,educational tool,decorative,animal figure,upright posture\n",
      "Similarity Score: 0.5447\n",
      "Description: This image features a three-dimensional bovine creature, typically known as a cow. It stands upright with clearly defined features including hooves, a tail, and a head with prominent ears and eyes. The texture appears smooth, and the coloration is uniform, suggesting it might be designed for educational or decorative purposes.\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank 3:\n",
      "ID: 117465\n",
      "Name: Cow 4929047 complete assembled whole img_\n",
      "Category: Animals\n",
      "Tags: cow,animal,assembled,detailed,lifelike,neutral pose\n",
      "Similarity Score: 0.5360\n",
      "Description: This is a 3D model of a cow. The cow is fully assembled and complete, capturing a high level of detail in its features. It is standing in a neutral pose, with all four legs firmly on the ground. The model showcases the cow's distinctive shape, including its large body, head with ears and horns, and the tail. The texture and color of the model further enhance its lifelike appearance.\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank 4:\n",
      "ID: 6181341\n",
      "Name: Cow diagram stencil 6181341 complete assembled whole img_\n",
      "Category: Educational Tools\n",
      "Tags: cow,stencil,anatomy,side view,educational,artistic\n",
      "Similarity Score: 0.5216\n",
      "Description: This is a three-dimensional stencil of a bovine figure. It features a side view of a cow, with distinct outlines for the head, body, legs, and tail. The design includes internal divisions suggesting different anatomical parts, making it suitable for educational purposes or artistic projects.\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank 5:\n",
      "ID: 561999\n",
      "Name: Fallout bessie 4733472 complete assembled whole img_\n",
      "Category: Video Game Characters\n",
      "Tags: robotic cow,video game,articulated joints,black and white,mechanical details,sensors,antennas,agricultural tools,weaponry\n",
      "Similarity Score: 0.5185\n",
      "Description: This appears to be a recreation of a robotic dairy cow, likely from a popular video game. The structure features a large, rounded body with distinct black and white patterning reminiscent of real-world dairy cows. It includes mechanical details such as visible joints and panels, indicating articulation points. The head is equipped with sensors and antennas, suggesting advanced functionality. Additional attachments on the sides and back could be interpreted as agricultural tools or weaponry.\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank 6:\n",
      "ID: 1081873\n",
      "Name: Highland cow 2555039 complete assembled whole img_\n",
      "Category: Animals\n",
      "Tags: highland cow,animal,fur texture,horns,standing position,realistic\n",
      "Similarity Score: 0.5115\n",
      "Description: This is a 3D model of a Highland cow. It appears to be a complete model with detailed features such as fur texture, horns, and facial features. The model seems well-assembled and depicts the cow in a standing position.\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank 7:\n",
      "ID: 6002710\n",
      "Name: Vache cow 4234630 complete assembled whole img_\n",
      "Category: Animal Figures\n",
      "Tags: bovine,four-legged,lifelike posture,smooth finish\n",
      "Similarity Score: 0.5089\n",
      "Description: This three-dimensional depiction showcases a bovine form, standing on all four legs with a typical stance. The figure is characterized by a well-defined body, complete with physical features such as hooves, ears, eyes, and a tail. Its surface appears smooth, suggesting a polished or refined finish. The posture is static, capturing the essence of a cow in a lifelike yet artistic manner.\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank 8:\n",
      "ID: 5033012\n",
      "Name: Spherical cow 5976438 complete assembled whole img_\n",
      "Category: Novelty Items\n",
      "Tags: spherical cow,humor,science joke,cartoonish design,simplified features,smooth texture,uniform color\n",
      "Similarity Score: 0.5039\n",
      "Description: A whimsical depiction of a spherical cow, crafted to emphasize a simplistic yet humorous approach to complex scientific calculations. This bovine creation features a perfectly round body with minimalistic, cartoonish details such as simplified legs, tail, and face features. Its surface is smooth, and it has a uniform color scheme that enhances its spherical design.\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank 9:\n",
      "ID: 4715681\n",
      "Name: Cow on grass 3d scanning tutorial! 3782602 complete assembled whole img_\n",
      "Category: Animals\n",
      "Tags: bovine,realistic texture,outdoor,grass,lifelike appearance\n",
      "Similarity Score: 0.4930\n",
      "Description: This is an image of a bovine creature, standing on a patch of grass. The animal is depicted with a high level of realism, featuring textured fur, distinct facial features such as eyes, ears, and nostrils, and a typical body structure with four legs and a tail. The surrounding grass is finely rendered, enhancing the lifelike appearance of the scene.\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank 10:\n",
      "ID: 161686\n",
      "Name: Cow 4058762 complete assembled whole img_\n",
      "Category: Animal Figures\n",
      "Tags: cow sculpture,realistic animal,grazing pose,lifelike texture,animal anatomy\n",
      "Similarity Score: 0.4915\n",
      "Description: An intricate bovine sculpture, featuring a standing cow with a detailed anatomy including distinct udders, hooves, and facial features. The texture mimics a realistic hide, complete with folds and creases, enhancing its lifelike appearance. Its pose is static, typical of a grazing animal, with alert ears and a calm expression.\n",
      "\n",
      "--------------------------------------------------\n",
      "Exiting Semantic Search. Goodbye!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f12d0d306aadf93b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
