{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Below is the code to make a knowledge graph, using information from the Thingiverse Scraper, like id number and description. From the description, information like its name and tags can also be scraped and are also used. Make sure that the csv path is the one for all scraped thingiverse models (there are around 980 on Github). Because this uses no AI, this is labeled the existing standard search that all other searches should be compared to in benchmarking.\n",
    "\n",
    "### Only main function and output are shown.\n"
   ],
   "id": "55e816d871a254e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def main(csv_path, k_threshold=True, k=1):\n",
    "#    \"\"\"\n",
    "#    Main function to orchestrate the semantic network construction.\n",
    "# \n",
    "#    Parameters:\n",
    "#    - csv_path (str): Path to the CSV file containing model descriptions.\n",
    "#    - k_threshold (bool): If True, apply dynamic thresholding using mean + k*std.\n",
    "#                           If False, do not apply dynamic thresholding.\n",
    "#    - k (float): The multiplier for the standard deviation in threshold calculation.\n",
    "#               Relevant only if k_threshold is True.\n",
    "# \n",
    "#    The function performs the following steps:\n",
    "#    1. Connects to Neo4j.\n",
    "#    2. Loads and preprocesses data.\n",
    "#    3. Extracts key components and expands synonyms.\n",
    "#    4. Performs Named Entity Recognition.\n",
    "#    5. Weights primary nouns and incorporates synonyms in descriptions.\n",
    "#    6. Calculates various similarity measures and combines them.\n",
    "#    7. Constructs the knowledge graph in Neo4j with nodes and edges.\n",
    "#    8. Applies additional optimizations like pruning and clustering.\n",
    "#    \"\"\"\n",
    "#    print(\"Starting semantic network construction process.\")\n",
    "# \n",
    "# \n",
    "#    # Step 1: Connect to Neo4j\n",
    "#    graph_db = connect_to_neo4j(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "# \n",
    "# \n",
    "#    # Step 2: Load Data\n",
    "#    df = load_data(csv_path)\n",
    "# \n",
    "# \n",
    "#    # Step 3: Preprocess Data (incorporate tags with higher weight)\n",
    "#    df = preprocess_dataframe(df)\n",
    "# \n",
    "# \n",
    "#    # Step 4: Extract Key Components\n",
    "#    df = extract_key_nouns_adjectives(df)\n",
    "#    df, synonym_dict = expand_synonyms(df)\n",
    "#    df = perform_ner(df)\n",
    "# \n",
    "# \n",
    "#    # Step 5: Preprocess Descriptions to Weight Primary Nouns and Incorporate Synonyms\n",
    "#    df = duplicate_primary_nouns(df, weight=2.0)\n",
    "# \n",
    "# \n",
    "#    # Step 6: Text Similarity Calculation\n",
    "#    tfidf_matrix, tfidf_vectorizer = compute_tfidf(df)\n",
    "#    cosine_sim = compute_cosine_similarity_matrix(tfidf_matrix)\n",
    "# \n",
    "# \n",
    "#    # Compute Sentence-BERT similarity using weighted_description\n",
    "#    embedding_sim = compute_sentence_transformer_similarity(df)\n",
    "# \n",
    "# \n",
    "#    # Since 'category' is omitted in this data, we skip it.\n",
    "#    category_sim = None\n",
    "# \n",
    "# \n",
    "#    # Compute the tag similarity\n",
    "#    tag_sim = compute_tag_similarity(df)\n",
    "# \n",
    "# \n",
    "#    # Combine all similarities into a hybrid matrix\n",
    "#    final_sim = hybrid_similarity(\n",
    "#        cosine_sim, embedding_sim, category_sim, tag_sim=tag_sim,\n",
    "#        weight_cosine=0.2, weight_embedding=0.45,\n",
    "#        weight_category=0.0, weight_tags=0.35\n",
    "#    )\n",
    "# \n",
    "# \n",
    "#    # Adjust similarity scores based on primary nouns\n",
    "#    final_sim = adjust_similarity_with_primary_nouns(df, final_sim, boost=1.2, penalize=0.8)\n",
    "# \n",
    "# \n",
    "#    # Adjust similarity scores based on entities\n",
    "#    final_sim = adjust_similarity_with_entities(df, final_sim, boost=1.2, penalize=0.8)\n",
    "# \n",
    "# \n",
    "#    # Normalize the final similarity matrix\n",
    "#    final_sim = normalize_similarity(final_sim)\n",
    "# \n",
    "# \n",
    "#    # Analyze similarity scores\n",
    "#    analyze_similarity_scores(final_sim)\n",
    "# \n",
    "# \n",
    "#    # Determine dynamic threshold if enabled\n",
    "#    if k_threshold:\n",
    "#        dynamic_threshold = determine_threshold_mean_std(final_sim, k=k)  # Can adjust k as needed\n",
    "#    else:\n",
    "#        dynamic_threshold = 0.0  # No thresholding; connect all relevant edges\n",
    "# \n",
    "# \n",
    "#    # Visualize similarity distribution with threshold\n",
    "#    visualize_similarity_distribution(\n",
    "#        final_sim,\n",
    "#        threshold=dynamic_threshold if k_threshold else None\n",
    "#    )\n",
    "# \n",
    "# \n",
    "#    # Step 7: Knowledge Graph Construction with Embeddings\n",
    "#    model = SentenceTransformer('all-MiniLM-L6-v2')  # Initialize Sentence-BERT model\n",
    "#    create_nodes_with_embeddings(graph_db, df, model)\n",
    "# \n",
    "# \n",
    "#    # Step 8: Create Edges Based on Similarity\n",
    "#    create_edges_batch(graph_db, df, final_sim, threshold=dynamic_threshold)  # Apply dynamic threshold\n",
    "# \n",
    "# \n",
    "#    # Step 9: Additional Optimizations\n",
    "#    graph_pruning(\n",
    "#        graph_db,\n",
    "#        threshold=dynamic_threshold if k_threshold else 0.0\n",
    "#    )  # Prune edges below the dynamic threshold\n",
    "#    node_clustering(\n",
    "#        graph_db, df, final_sim, threshold=dynamic_threshold\n",
    "#    )  # Cluster based on dynamic threshold\n",
    "# \n",
    "# \n",
    "#    print(\"Knowledge graph construction complete.\")\n",
    "# \n",
    "# \n",
    "# if __name__ == \"__main__\":\n",
    "#    # Set k_threshold=True to enable dynamic thresholding\n",
    "#    # Set k_threshold=False to disable dynamic thresholding\n",
    "#    # Adjust k as needed (e.g., k=1 for mean + 1*std)\n",
    "#    main(CSV_PATH, k_threshold=True, k=2)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Below this is the code that allows the user to search for their specific model (model_search.py) using the knowledge graph constructed above. There is also filtering, selection, research, and other useful functionalities.\n",
    "\n",
    "### Only main function and output are shown.\n"
   ],
   "id": "3d53b8b84ad90b8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# def main():\n",
    "#     \"\"\"\n",
    "#     Main function to handle user queries and perform search on the knowledge graph with cascading filtering.\n",
    "#     \"\"\"\n",
    "#     print(\"Initializing Semantic Search on Knowledge Graph...\")\n",
    "# \n",
    "#     # Connect to Neo4j\n",
    "#     graph_db = connect_to_neo4j(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "# \n",
    "#     # Fetch all models with embeddings\n",
    "#     df_models = fetch_all_models(graph_db)\n",
    "# \n",
    "#     # Extract embeddings as a 2D numpy array\n",
    "#     model_embeddings = np.stack(df_models['embedding'].values)\n",
    "# \n",
    "#     # Load Sentence Transformer model\n",
    "#     print(\"Loading SentenceTransformer model...\")\n",
    "#     model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#     print(\"Model loaded successfully.\")\n",
    "# \n",
    "#     while True:\n",
    "#         # Prompt user for input\n",
    "#         user_query = input(\"\\nEnter your search query (or type 'exit' to quit): \").strip()\n",
    "#         if user_query.lower() == 'exit':\n",
    "#             print(\"Exiting Semantic Search. Goodbye!\")\n",
    "#             break\n",
    "#         if not user_query:\n",
    "#             print(\"Empty query. Please enter a valid search term.\")\n",
    "#             continue\n",
    "# \n",
    "#         # Preprocess the query with dynamic prioritization\n",
    "#         preprocessed_query = preprocess_text(user_query)\n",
    "#         if not preprocessed_query:\n",
    "#             print(\"Failed to preprocess the query. Please try a different input.\")\n",
    "#             continue\n",
    "# \n",
    "#         # Encode the query\n",
    "#         query_embedding = model.encode(preprocessed_query, show_progress_bar=False)\n",
    "# \n",
    "#         # Compute cosine similarity\n",
    "#         print(\"Computing similarities...\")\n",
    "#         similarities = compute_cosine_similarity(query_embedding, model_embeddings)\n",
    "# \n",
    "#         if similarities.size == 0:\n",
    "#             print(\"Failed to compute similarities.\")\n",
    "#             continue\n",
    "# \n",
    "#         # Display the top-k results\n",
    "#         top_k = 10  # Number of top results to retrieve\n",
    "#         top_results = display_results(df_models, similarities, top_k=top_k)\n",
    "# \n",
    "#         if top_results is None or top_results.empty:\n",
    "#             print(\"No similar models found.\")\n",
    "#             continue\n",
    "# \n",
    "#         # Initialize the current search scope with the initial top results\n",
    "#         current_scope = top_results\n",
    "# \n",
    "#         while True:\n",
    "#             # Prompt user to apply further filters or select a model\n",
    "#             selected = prompt_filter(current_scope)\n",
    "#             if selected == 'yes':\n",
    "#                 # User wants to filter further\n",
    "#                 # Prompt to select a model from current_scope\n",
    "#                 try:\n",
    "#                     selection = int(input(f\"Select a model to filter by (1-{len(current_scope)}): \").strip())\n",
    "#                     if 1 <= selection <= len(current_scope):\n",
    "#                         selected_model = current_scope.iloc[selection - 1]\n",
    "#                         selected_model_id = selected_model['id']\n",
    "#                         print(f\"\\nSelected Model ID: {selected_model_id} - {selected_model['name'] if pd.notnull(selected_model['name']) else 'N/A'}\")\n",
    "#                     else:\n",
    "#                         print(f\"Please enter a number between 1 and {len(current_scope)}.\")\n",
    "#                         continue\n",
    "#                 except ValueError:\n",
    "#                     print(\"Invalid input. Please enter a valid number.\")\n",
    "#                     continue\n",
    "# \n",
    "#                 # Fetch similar models to the selected model from the graph\n",
    "#                 similar_df = fetch_similar_models_from_graph(graph_db, selected_model_id)\n",
    "# \n",
    "#                 if similar_df.empty:\n",
    "#                     print(\"No further models found based on your selection.\")\n",
    "#                     break  # Exit filtering loop\n",
    "# \n",
    "#                 # Display the new set of similar models\n",
    "#                 print(f\"\\nModels similar to Model ID: {selected_model_id}:\")\n",
    "#                 similar_top_k = 10  # Number of top similar models to display\n",
    "#                 similar_top_results = display_results(similar_df, similar_df['similarity'].values, top_k=similar_top_k)\n",
    "# \n",
    "#                 if similar_top_results is None or similar_top_results.empty:\n",
    "#                     print(\"No similar models found in this step.\")\n",
    "#                     break  # Exit filtering loop\n",
    "# \n",
    "#                 # Update the current scope to the new similar models\n",
    "#                 current_scope = similar_top_results\n",
    "# \n",
    "#             elif selected == 'no':\n",
    "#                 # User does not want to filter further\n",
    "#                 break  # Exit filtering loop\n",
    "#             else:\n",
    "#                 # User selected a model by rank to view its full summary\n",
    "#                 selected_model_id = selected\n",
    "#                 # Fetch the full details of the selected model\n",
    "#                 try:\n",
    "#                     query = \"\"\"\n",
    "#                     MATCH (m:Model {id: $selected_id})\n",
    "#                     RETURN m.id AS id, m.name AS name, m.description AS description, m.category AS category, m.tags AS tags\n",
    "#                     \"\"\"\n",
    "#                     record = graph_db.run(query, selected_id=selected_model_id).data()\n",
    "#                     if not record:\n",
    "#                         print(f\"No details found for Model ID: {selected_model_id}.\")\n",
    "#                     else:\n",
    "#                         model_details = record[0]\n",
    "#                         print(f\"\\n--- Full Summary of Selected Model ---\")\n",
    "#                         print(f\"ID: {model_details['id']}\")\n",
    "#                         print(f\"Name: {model_details['name'] if pd.notnull(model_details['name']) else 'N/A'}\")\n",
    "#                         print(f\"Category: {model_details['category'] if pd.notnull(model_details['category']) else 'N/A'}\")\n",
    "#                         print(f\"Tags: {model_details['tags'] if pd.notnull(model_details['tags']) else 'N/A'}\")\n",
    "#                         print(f\"Description: {model_details['description'] if pd.notnull(model_details['description']) else 'N/A'}\")\n",
    "#                         print(f\"---------------------------------------\\n\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error fetching model details: {e}\")\n",
    "# \n",
    "#                 # After displaying the summary, ask if the user wants another search\n",
    "#                 while True:\n",
    "#                     another_search = input(\"Do you want to perform another search? (yes/no): \").strip().lower()\n",
    "#                     if another_search in ['yes', 'y']:\n",
    "#                         break  # Break to the main search loop\n",
    "#                     elif another_search in ['no', 'n']:\n",
    "#                         print(\"Exiting Semantic Search. Goodbye!\")\n",
    "#                         sys.exit(0)\n",
    "#                     else:\n",
    "#                         print(\"Please answer with 'yes' or 'no'.\")\n",
    "#                 break  # Exit filtering loop to perform another search\n",
    "# \n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ],
   "id": "82497a9b64b3a73f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
